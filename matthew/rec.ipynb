{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time as tm\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.knns import KNNWithMeans\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore\n",
    "from surprise.prediction_algorithms.knns import KNNBaseline\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVDpp\n",
    "from surprise.prediction_algorithms.matrix_factorization import NMF\n",
    "from surprise.prediction_algorithms.slope_one import SlopeOne\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection.search import GridSearchCV\n",
    "\n",
    "reviewsPath = 'data/reviews_ssc.csv'\n",
    "df_reviews = pd.read_csv(reviewsPath, sep=',')\n",
    "df_reviews['unixReviewTime'] = pd.to_numeric(df_reviews['unixReviewTime'], errors='coerce')\n",
    "#print(df_reviews.head())\n",
    "\n",
    "userLocationPath = 'data/user_locations.csv'\n",
    "df_userLocations = pd.read_csv(userLocationPath, sep=',')\n",
    "#print(df_userLocations.head())\n",
    "\n",
    "userReviewsPath = 'data/filtered_reviews_by_user.csv'\n",
    "df_userReviews = pd.read_csv(userReviewsPath, sep=',')\n",
    "#print(df_userReviews.head())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "grouped = df_reviews.groupby('gPlusUserId', as_index=False)['rating']\n",
    "means = grouped.mean()\n",
    "mins = grouped.min()\n",
    "maxs = grouped.max()\n",
    "\n",
    "meanTime = df_reviews['unixReviewTime'].mean()\n",
    "maxTime = df_reviews['unixReviewTime'].max()\n",
    "minTime = df_reviews['unixReviewTime'].min()\n",
    "#print(means[means['gPlusUserId'] == '100003840837471130074']['rating'])\n",
    "\n",
    "meanRating = []\n",
    "timeRating = []\n",
    "meanTimeRating = []\n",
    "diff = float(maxTime - minTime)\n",
    "for i in range(df_reviews.shape[0]):\n",
    "    a = float(df_reviews['unixReviewTime'][i]) if pd.notna(df_reviews['unixReviewTime'][i]) else maxTime\n",
    "    b = (a - minTime) / diff\n",
    "    mn = means[means['gPlusUserId'] == df_reviews['gPlusUserId'][i]]['rating']\n",
    "    d = float(df_reviews['rating'][i] - mn)\n",
    "    \n",
    "    meanRating.append(d)\n",
    "    timeRating.append(df_reviews['rating'][i] * b)\n",
    "    if d >= 0 or b == 0.0:\n",
    "        meanTimeRating.append(d * b)\n",
    "    else:\n",
    "        meanTimeRating.append(d / b)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0093\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# raw ratings\n",
    "reader = Reader(rating_scale=(1,5), skip_lines=1)\n",
    "reviewsData = Dataset.load_from_df(df_reviews[['gPlusUserId', 'gPlusPlaceId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(reviewsData, test_size=.25)\n",
    "\n",
    "algo = SVD(n_factors=200,n_epochs=50,lr_bu=0.005,lr_bi=0.005,lr_pu=0.005,\n",
    "           lr_qi=0.001,reg_bu=0.05,reg_bi=0.02,reg_pu=0.05,reg_qi=0.05)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9574\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# normalized by timestamp\n",
    "df_reviews['timeRating'] = timeRating\n",
    "#print(df_reviews['timeRating'])\n",
    "reader = Reader(rating_scale=(0,5), skip_lines=1)\n",
    "reviewsData = Dataset.load_from_df(df_reviews[['gPlusUserId', 'gPlusPlaceId', 'timeRating']], reader)\n",
    "trainset, testset = train_test_split(reviewsData, test_size=.25)\n",
    "\n",
    "algo = SVD(n_factors=200,n_epochs=50,lr_bu=0.005,lr_bi=0.005,lr_pu=0.005,\n",
    "           lr_qi=0.001,reg_bu=0.05,reg_bi=0.02,reg_pu=0.05,reg_qi=0.05)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7507\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# normalized by user mean\n",
    "df_reviews['meanRating'] = meanRating\n",
    "reader = Reader(rating_scale=(-4,5), skip_lines=1)\n",
    "reviewsData = Dataset.load_from_df(df_reviews[['gPlusUserId', 'gPlusPlaceId', 'meanRating']], reader)\n",
    "trainset, testset = train_test_split(reviewsData, test_size=.25)\n",
    "\n",
    "algo = SVD(n_factors=200,n_epochs=50,lr_bu=0.005,lr_bi=0.005,lr_pu=0.005,\n",
    "           lr_qi=0.001,reg_bu=0.05,reg_bi=0.02,reg_pu=0.05,reg_qi=0.05)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7566\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# normalized by user mean and timestamp\n",
    "df_reviews['meanTimeRating'] = meanTimeRating\n",
    "reader = Reader(rating_scale=(-4,5), skip_lines=1)\n",
    "reviewsData = Dataset.load_from_df(df_reviews[['gPlusUserId', 'gPlusPlaceId', 'meanTimeRating']], reader)\n",
    "trainset, testset = train_test_split(reviewsData, test_size=.25)\n",
    "\n",
    "algo = SVD(n_factors=200,n_epochs=50,lr_bu=0.005,lr_bi=0.005,lr_pu=0.005,\n",
    "           lr_qi=0.001,reg_bu=0.05,reg_bi=0.02,reg_pu=0.05,reg_qi=0.05)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_top_n(df,tr,n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))'''\n",
    "    \n",
    "    header = ['uid']\n",
    "    # assumes i < 1000\n",
    "    for i in range(1,n+1):\n",
    "        header.append('iid{:03d}'.format(i))\n",
    "    csv.register_dialect('myDialect', delimiter = ',', quoting=csv.QUOTE_NONE, skipinitialspace=True)\n",
    "    baseFilename = 'top{}'.format(n)\n",
    "    timeString = dt.datetime.fromtimestamp(tm.time()).strftime('_%y%m%d_%H%M%S')\n",
    "    \n",
    "    with open(baseFilename+timeString+'.csv', 'w') as f:\n",
    "        writer = csv.writer(f, dialect='myDialect')\n",
    "        writer.writerow(header)\n",
    "\n",
    "        print('fitting model...')\n",
    "        algo = SVD(n_factors=200,n_epochs=50,lr_bu=0.005,lr_bi=0.005,lr_pu=0.005,\n",
    "           lr_qi=0.001,reg_bu=0.05,reg_bi=0.02,reg_pu=0.05,reg_qi=0.05)\n",
    "        algo.fit(tr)\n",
    "        \n",
    "        print('filling csv...')\n",
    "        usersRemaining = tr.n_users\n",
    "        for u in tr.all_users():\n",
    "            predictedRatings = []\n",
    "            rawUid = tr.to_raw_uid(u)\n",
    "            userRatings = df.loc[df['gPlusUserId'] == rawUid]['gPlusPlaceId'].tolist()\n",
    "            for i in tr.all_items():\n",
    "                rawIid = tr.to_raw_iid(i)\n",
    "                if rawIid not in userRatings:\n",
    "                    p = algo.predict(rawUid,rawIid)\n",
    "                    predictedRatings.append((p.iid, p.est))\n",
    "            \n",
    "            predictedRatings.sort(key=lambda x: x[1], reverse=True)\n",
    "            writer.writerow([rawUid]+[iid for (iid, _) in predictedRatings[:n]])\n",
    "                    \n",
    "            usersRemaining -= 1\n",
    "            if usersRemaining % 200 == 0:\n",
    "                print(usersRemaining)\n",
    "            #print(ps)\n",
    "        \n",
    "        '''\n",
    "        togo = len(top_n.items())\n",
    "        for uid, ratings in top_n.items():\n",
    "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            #top_n[uid] = user_ratings[:n]\n",
    "            writer.writerow([uid]+[iid for (iid, _) in ratings[:n]])\n",
    "            togo -= 1\n",
    "            print('{} {}'.format(togo, uid))'''\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "def writeCsv(resultsList, baseFilename):\n",
    "  newList = [['uid','iid01','iid02','iid03','iid04','iid05','iid06','iid07','iid08','iid09','iid10']] + [[uid]+[iid for (iid, _) in ratings] for uid,ratings in resultsList]\n",
    "  csv.register_dialect('myDialect', delimiter = ',', quoting=csv.QUOTE_NONE, skipinitialspace=True)\n",
    "  timeString = dt.datetime.fromtimestamp(tm.time()).strftime('_%y%m%d_%H%M%S')\n",
    "\n",
    "  with open(baseFilename+timeString+'.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    for row in newList:\n",
    "      writer.writerow(row)\n",
    "\n",
    "  f.close()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model...\n",
      "filling csv...\n",
      "26200\n",
      "26000\n",
      "25800\n",
      "25600\n",
      "25400\n",
      "25200\n",
      "25000\n",
      "24800\n",
      "24600\n",
      "24400\n",
      "24200\n",
      "24000\n",
      "23800\n",
      "23600\n",
      "23400\n",
      "23200\n",
      "23000\n",
      "22800\n",
      "22600\n",
      "22400\n",
      "22200\n",
      "22000\n",
      "21800\n",
      "21600\n",
      "21400\n",
      "21200\n",
      "21000\n",
      "20800\n",
      "20600\n",
      "20400\n",
      "20200\n",
      "20000\n",
      "19800\n",
      "19600\n",
      "19400\n",
      "19200\n",
      "19000\n",
      "18800\n",
      "18600\n",
      "18400\n",
      "18200\n",
      "18000\n",
      "17800\n",
      "17600\n",
      "17400\n",
      "17200\n",
      "17000\n",
      "16800\n",
      "16600\n",
      "16400\n",
      "16200\n",
      "16000\n",
      "15800\n",
      "15600\n",
      "15400\n",
      "15200\n",
      "15000\n",
      "14800\n",
      "14600\n",
      "14400\n",
      "14200\n",
      "14000\n",
      "13800\n",
      "13600\n",
      "13400\n",
      "13200\n",
      "13000\n",
      "12800\n",
      "12600\n",
      "12400\n",
      "12200\n",
      "12000\n",
      "11800\n",
      "11600\n",
      "11400\n",
      "11200\n",
      "11000\n",
      "10800\n",
      "10600\n",
      "10400\n",
      "10200\n",
      "10000\n",
      "9800\n",
      "9600\n",
      "9400\n",
      "9200\n",
      "9000\n",
      "8800\n",
      "8600\n",
      "8400\n",
      "8200\n",
      "8000\n",
      "7800\n",
      "7600\n",
      "7400\n",
      "7200\n",
      "7000\n",
      "6800\n",
      "6600\n",
      "6400\n",
      "6200\n",
      "6000\n",
      "5800\n",
      "5600\n",
      "5400\n",
      "5200\n",
      "5000\n",
      "4800\n",
      "4600\n",
      "4400\n",
      "4200\n",
      "4000\n",
      "3800\n",
      "3600\n",
      "3400\n",
      "3200\n",
      "3000\n",
      "2800\n",
      "2600\n",
      "2400\n",
      "2200\n",
      "2000\n",
      "1800\n",
      "1600\n",
      "1400\n",
      "1200\n",
      "1000\n",
      "800\n",
      "600\n",
      "400\n",
      "200\n",
      "0\n",
      "fitting model...\n",
      "filling csv...\n",
      "26200\n",
      "26000\n",
      "25800\n",
      "25600\n",
      "25400\n",
      "25200\n",
      "25000\n",
      "24800\n",
      "24600\n",
      "24400\n",
      "24200\n",
      "24000\n",
      "23800\n",
      "23600\n",
      "23400\n",
      "23200\n",
      "23000\n",
      "22800\n",
      "22600\n",
      "22400\n",
      "22200\n",
      "22000\n",
      "21800\n",
      "21600\n",
      "21400\n",
      "21200\n",
      "21000\n",
      "20800\n",
      "20600\n",
      "20400\n",
      "20200\n",
      "20000\n",
      "19800\n",
      "19600\n",
      "19400\n",
      "19200\n",
      "19000\n",
      "18800\n",
      "18600\n",
      "18400\n",
      "18200\n",
      "18000\n",
      "17800\n",
      "17600\n",
      "17400\n",
      "17200\n",
      "17000\n",
      "16800\n",
      "16600\n",
      "16400\n",
      "16200\n",
      "16000\n",
      "15800\n",
      "15600\n",
      "15400\n",
      "15200\n",
      "15000\n",
      "14800\n",
      "14600\n",
      "14400\n",
      "14200\n",
      "14000\n",
      "13800\n",
      "13600\n",
      "13400\n",
      "13200\n",
      "13000\n",
      "12800\n",
      "12600\n",
      "12400\n",
      "12200\n",
      "12000\n",
      "11800\n",
      "11600\n",
      "11400\n",
      "11200\n",
      "11000\n",
      "10800\n",
      "10600\n",
      "10400\n",
      "10200\n",
      "10000\n",
      "9800\n",
      "9600\n",
      "9400\n",
      "9200\n",
      "9000\n",
      "8800\n",
      "8600\n",
      "8400\n",
      "8200\n",
      "8000\n",
      "7800\n",
      "7600\n",
      "7400\n",
      "7200\n",
      "7000\n",
      "6800\n",
      "6600\n",
      "6400\n",
      "6200\n",
      "6000\n",
      "5800\n",
      "5600\n",
      "5400\n",
      "5200\n",
      "5000\n",
      "4800\n",
      "4600\n",
      "4400\n",
      "4200\n",
      "4000\n",
      "3800\n",
      "3600\n",
      "3400\n",
      "3200\n",
      "3000\n",
      "2800\n",
      "2600\n",
      "2400\n",
      "2200\n",
      "2000\n",
      "1800\n",
      "1600\n",
      "1400\n",
      "1200\n",
      "1000\n",
      "800\n",
      "600\n",
      "400\n",
      "200\n",
      "0\n",
      "fitting model...\n",
      "filling csv...\n",
      "26200\n",
      "26000\n",
      "25800\n",
      "25600\n",
      "25400\n",
      "25200\n",
      "25000\n",
      "24800\n",
      "24600\n",
      "24400\n",
      "24200\n",
      "24000\n",
      "23800\n",
      "23600\n",
      "23400\n",
      "23200\n",
      "23000\n",
      "22800\n",
      "22600\n",
      "22400\n",
      "22200\n",
      "22000\n",
      "21800\n",
      "21600\n",
      "21400\n",
      "21200\n",
      "21000\n",
      "20800\n",
      "20600\n",
      "20400\n",
      "20200\n",
      "20000\n",
      "19800\n",
      "19600\n",
      "19400\n",
      "19200\n",
      "19000\n",
      "18800\n",
      "18600\n",
      "18400\n",
      "18200\n",
      "18000\n",
      "17800\n",
      "17600\n",
      "17400\n",
      "17200\n",
      "17000\n",
      "16800\n",
      "16600\n",
      "16400\n",
      "16200\n",
      "16000\n",
      "15800\n",
      "15600\n",
      "15400\n",
      "15200\n",
      "15000\n",
      "14800\n",
      "14600\n",
      "14400\n",
      "14200\n",
      "14000\n",
      "13800\n",
      "13600\n",
      "13400\n",
      "13200\n",
      "13000\n",
      "12800\n",
      "12600\n",
      "12400\n",
      "12200\n",
      "12000\n",
      "11800\n",
      "11600\n",
      "11400\n",
      "11200\n",
      "11000\n",
      "10800\n",
      "10600\n",
      "10400\n",
      "10200\n",
      "10000\n",
      "9800\n",
      "9600\n",
      "9400\n",
      "9200\n",
      "9000\n",
      "8800\n",
      "8600\n",
      "8400\n",
      "8200\n",
      "8000\n",
      "7800\n",
      "7600\n",
      "7400\n",
      "7200\n",
      "7000\n",
      "6800\n",
      "6600\n",
      "6400\n",
      "6200\n",
      "6000\n",
      "5800\n",
      "5600\n",
      "5400\n",
      "5200\n",
      "5000\n",
      "4800\n",
      "4600\n",
      "4400\n",
      "4200\n",
      "4000\n",
      "3800\n",
      "3600\n",
      "3400\n",
      "3200\n",
      "3000\n",
      "2800\n",
      "2600\n",
      "2400\n",
      "2200\n",
      "2000\n",
      "1800\n",
      "1600\n",
      "1400\n",
      "1200\n",
      "1000\n",
      "800\n",
      "600\n",
      "400\n",
      "200\n",
      "0\n",
      "fitting model...\n",
      "filling csv...\n",
      "26200\n",
      "26000\n",
      "25800\n",
      "25600\n",
      "25400\n",
      "25200\n",
      "25000\n",
      "24800\n",
      "24600\n",
      "24400\n",
      "24200\n",
      "24000\n",
      "23800\n",
      "23600\n",
      "23400\n",
      "23200\n",
      "23000\n",
      "22800\n",
      "22600\n",
      "22400\n",
      "22200\n",
      "22000\n",
      "21800\n",
      "21600\n",
      "21400\n",
      "21200\n",
      "21000\n",
      "20800\n",
      "20600\n",
      "20400\n",
      "20200\n",
      "20000\n",
      "19800\n",
      "19600\n",
      "19400\n",
      "19200\n",
      "19000\n",
      "18800\n",
      "18600\n",
      "18400\n",
      "18200\n",
      "18000\n",
      "17800\n",
      "17600\n",
      "17400\n",
      "17200\n",
      "17000\n",
      "16800\n",
      "16600\n",
      "16400\n",
      "16200\n",
      "16000\n",
      "15800\n",
      "15600\n",
      "15400\n",
      "15200\n",
      "15000\n",
      "14800\n",
      "14600\n",
      "14400\n",
      "14200\n",
      "14000\n",
      "13800\n",
      "13600\n",
      "13400\n",
      "13200\n",
      "13000\n",
      "12800\n",
      "12600\n",
      "12400\n",
      "12200\n",
      "12000\n",
      "11800\n",
      "11600\n",
      "11400\n",
      "11200\n",
      "11000\n",
      "10800\n",
      "10600\n",
      "10400\n",
      "10200\n",
      "10000\n",
      "9800\n",
      "9600\n",
      "9400\n",
      "9200\n",
      "9000\n",
      "8800\n",
      "8600\n",
      "8400\n",
      "8200\n",
      "8000\n",
      "7800\n",
      "7600\n",
      "7400\n",
      "7200\n",
      "7000\n",
      "6800\n",
      "6600\n",
      "6400\n",
      "6200\n",
      "6000\n",
      "5800\n",
      "5600\n",
      "5400\n",
      "5200\n",
      "5000\n",
      "4800\n",
      "4600\n",
      "4400\n",
      "4200\n",
      "4000\n",
      "3800\n",
      "3600\n",
      "3400\n",
      "3200\n",
      "3000\n",
      "2800\n",
      "2600\n",
      "2400\n",
      "2200\n",
      "2000\n",
      "1800\n",
      "1600\n",
      "1400\n",
      "1200\n",
      "1000\n",
      "800\n",
      "600\n",
      "400\n",
      "200\n",
      "0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1,5), skip_lines=1)\n",
    "useCols = df_reviews[['gPlusUserId', 'gPlusPlaceId', 'rating']]\n",
    "reviewsData = Dataset.load_from_df(useCols, reader)\n",
    "trainset = reviewsData.build_full_trainset()\n",
    "get_top_n(useCols, trainset, n=20)\n",
    "\n",
    "reader = Reader(rating_scale=(0,5), skip_lines=1)\n",
    "useCols = df_reviews[['gPlusUserId', 'gPlusPlaceId', 'timeRating']]\n",
    "reviewsData = Dataset.load_from_df(useCols, reader)\n",
    "trainset = reviewsData.build_full_trainset()\n",
    "get_top_n(useCols, trainset, n=20)\n",
    "\n",
    "reader = Reader(rating_scale=(-4,5), skip_lines=1)\n",
    "useCols = df_reviews[['gPlusUserId', 'gPlusPlaceId', 'meanRating']]\n",
    "reviewsData = Dataset.load_from_df(useCols, reader)\n",
    "trainset = reviewsData.build_full_trainset()\n",
    "get_top_n(useCols, trainset, n=20)\n",
    "\n",
    "reader = Reader(rating_scale=(-4,5), skip_lines=1)\n",
    "useCols = df_reviews[['gPlusUserId', 'gPlusPlaceId', 'meanTimeRating']]\n",
    "reviewsData = Dataset.load_from_df(useCols, reader)\n",
    "trainset = reviewsData.build_full_trainset()\n",
    "get_top_n(useCols, trainset, n=20)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
